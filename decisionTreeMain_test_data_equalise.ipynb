{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "from numpy import genfromtxt\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, cohen_kappa_score, mean_absolute_error, balanced_accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.preprocessing import normalize\n",
    "import graphviz \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import SVG\n",
    "\n",
    "from IPython.display import Image  \n",
    "\n",
    "#----------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#set image size\n",
    "num_pixels = 24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing training  data from CSV files\n",
    "x_train_import = genfromtxt('x_train_gr_smpl.csv', delimiter=',', skip_header =1)\n",
    "y_train_import = genfromtxt('y_train_smpl.csv', delimiter=',', skip_header =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing testing data from CSV files\n",
    "x_test_import = genfromtxt('x_test_gr_smpl.csv', delimiter=',', skip_header =1)\n",
    "y_test_import = genfromtxt('y_test_smpl.csv', delimiter=',', skip_header =1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12660, 2304)\n",
      "(12660,)\n",
      "(4170, 2304)\n",
      "(4170,)\n"
     ]
    }
   ],
   "source": [
    "# Check data has been imported correctly \n",
    "print(x_train_import.shape)\n",
    "print(y_train_import.shape)\n",
    "print(x_test_import.shape)\n",
    "print(y_test_import.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinging data with labels\n",
    "\n",
    "y_train_import = y_train_import.reshape(12660,1)\n",
    "train_data_combined = np.append(x_train_import, y_train_import, axis=1)\n",
    "\n",
    "y_test_import = y_test_import.reshape(4170,1)\n",
    "test_data_combined = np.append(x_test_import, y_test_import, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomises row order in a reproducable way \n",
    "np.random.seed(0)\n",
    "np.random.shuffle(train_data_combined)\n",
    "np.random.shuffle(test_data_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 2400\n"
     ]
    }
   ],
   "source": [
    "#equalize the data so all classes have the same amount of instances - smaller classes take their max\n",
    "\n",
    "def equilize(data):\n",
    "    train_combined_equal = []\n",
    "    for x in range(10):\n",
    "        count = 0\n",
    "        #while count < 240:\n",
    "        for i in data :\n",
    "            if i[-1] == x and count < 240:\n",
    "                train_combined_equal.append(i)\n",
    "                count += 1\n",
    "        \n",
    "    train_combined_equal = np.asarray(train_combined_equal)\n",
    "    np.random.shuffle(train_combined_equal)      \n",
    "    \n",
    "    return train_combined_equal\n",
    "\n",
    "train_combined_equal = equilize(train_data_combined)\n",
    "print(\"length:\",len(train_combined_equal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean: 80.40806694878472\n",
      "test mean: 85.48841426858513\n"
     ]
    }
   ],
   "source": [
    "# Split data and lables that have undergone the same randomization process \n",
    "x_train = train_combined_equal[:,:-1]\n",
    "y_train = train_combined_equal[:, [-1]].reshape(len(train_combined_equal),)   \n",
    "\n",
    "\n",
    "x_train_all = train_data_combined[:,:-1]\n",
    "y_train_all = train_data_combined[:, [-1]].reshape(12660,)\n",
    "\n",
    "x_test = test_data_combined[:,:-1]\n",
    "y_test = test_data_combined[:, [-1]].reshape(4170,)\n",
    "\n",
    "#what is the mean of the data\n",
    "print(\"train mean:\",np.mean(x_train))\n",
    "print(\"test mean:\",np.mean(x_test))\n",
    "#shows that test set has been offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Reducing the number of attributes using opencv's reduce functionality as shown in the second python Lecture\n",
    "#  As seen in python lectures: https://vision.hw.ac.uk/webapps/blackboard/content/listContent.jsp?course_id=_94419_1&content_id=_3391865_1\n",
    "x_train_all = np.apply_along_axis(\n",
    "        func1d=lambda img: cv2.resize(img.reshape((48,48)), (num_pixels,num_pixels)),\n",
    "        axis =1, arr = x_train_all).reshape((-1,num_pixels*num_pixels))\n",
    "\n",
    "x_train = np.apply_along_axis(\n",
    "        func1d=lambda img: cv2.resize(img.reshape((48,48)), (num_pixels,num_pixels)),\n",
    "        axis =1, arr = x_train).reshape((-1,num_pixels*num_pixels))\n",
    "\n",
    "x_test  = np.apply_along_axis(\n",
    "        func1d=lambda img: cv2.resize(img.reshape((48,48)), (num_pixels,num_pixels)),\n",
    "        axis =1, arr = x_test).reshape((-1,num_pixels*num_pixels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_test = np.append(x_train,x_test, axis=0)\n",
    "y_train_test = np.append(y_train,y_test, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Kappa score vs MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try standared tree with no limits \n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "# graph = graphviz.Source(tree.export_graphviz(clf, out_file=None,filled=True,rounded=True,class_names=True))  \n",
    "# png_bytes = graph.pipe(format='png')  \n",
    "# name = \"overfitting_base_tree.png\"\n",
    "# with open(name,'wb') as f:\n",
    "#     f.write(png_bytes)\n",
    "\n",
    "# Image(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.44      0.45       450\n",
      "         1.0       0.47      0.53      0.50       630\n",
      "         2.0       0.37      0.29      0.32       150\n",
      "         3.0       0.80      0.81      0.81       420\n",
      "         4.0       0.66      0.53      0.59       690\n",
      "         5.0       0.80      0.80      0.80       720\n",
      "         6.0       0.75      0.77      0.76       270\n",
      "         7.0       0.05      0.13      0.07        60\n",
      "         8.0       0.70      0.66      0.68       690\n",
      "         9.0       0.22      0.37      0.28        90\n",
      "\n",
      "    accuracy                           0.61      4170\n",
      "   macro avg       0.53      0.53      0.53      4170\n",
      "weighted avg       0.63      0.61      0.62      4170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predict on test set\n",
    "y_pred_test_data = clf.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa: 0.5558382686842063\n",
      "MAE: 1.1995203836930455\n"
     ]
    }
   ],
   "source": [
    "print(\"kappa:\",cohen_kappa_score(y_test, y_pred_test_data))\n",
    "print(\"MAE:\",mean_absolute_error(y_test, y_pred_test_data))# kappa greater then good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The same procedure for 1360 images of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 9660\n"
     ]
    }
   ],
   "source": [
    "#equalize the data so all classes have the same amount of instances - smaller classes take their max\n",
    "\n",
    "def equilize(data):\n",
    "    train_combined_equal = []\n",
    "    for x in range(10):\n",
    "        count = 0\n",
    "        #while count < 1320:\n",
    "        for i in data :\n",
    "            if i[-1] == x and count < 1320:\n",
    "                train_combined_equal.append(i)\n",
    "                count += 1\n",
    "        \n",
    "    train_combined_equal = np.asarray(train_combined_equal)\n",
    "    np.random.shuffle(train_combined_equal)      \n",
    "    \n",
    "    return train_combined_equal\n",
    "\n",
    "train_combined_equal = equilize(train_data_combined)\n",
    "print(\"length:\",len(train_combined_equal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean: 80.58911520337301\n",
      "test mean: 85.48841426858513\n"
     ]
    }
   ],
   "source": [
    "# Split data and lables that have undergone the same randomization process \n",
    "x_train = train_combined_equal[:,:-1]\n",
    "y_train = train_combined_equal[:, [-1]].reshape(len(train_combined_equal),)   \n",
    "\n",
    "\n",
    "x_train_all = train_data_combined[:,:-1]\n",
    "y_train_all = train_data_combined[:, [-1]].reshape(12660,)\n",
    "\n",
    "x_test = test_data_combined[:,:-1]\n",
    "y_test = test_data_combined[:, [-1]].reshape(4170,)\n",
    "\n",
    "#what is the mean of the data\n",
    "print(\"train mean:\",np.mean(x_train))\n",
    "print(\"test mean:\",np.mean(x_test))\n",
    "#shows that test set has been offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Reducing the number of attributes using opencv's reduce functionality as shown in the second python Lecture\n",
    "#  As seen in python lectures: https://vision.hw.ac.uk/webapps/blackboard/content/listContent.jsp?course_id=_94419_1&content_id=_3391865_1\n",
    "x_train_all = np.apply_along_axis(\n",
    "        func1d=lambda img: cv2.resize(img.reshape((48,48)), (num_pixels,num_pixels)),\n",
    "        axis =1, arr = x_train_all).reshape((-1,num_pixels*num_pixels))\n",
    "\n",
    "x_train = np.apply_along_axis(\n",
    "        func1d=lambda img: cv2.resize(img.reshape((48,48)), (num_pixels,num_pixels)),\n",
    "        axis =1, arr = x_train).reshape((-1,num_pixels*num_pixels))\n",
    "\n",
    "x_test  = np.apply_along_axis(\n",
    "        func1d=lambda img: cv2.resize(img.reshape((48,48)), (num_pixels,num_pixels)),\n",
    "        axis =1, arr = x_test).reshape((-1,num_pixels*num_pixels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_test = np.append(x_train,x_test, axis=0)\n",
    "y_train_test = np.append(y_train,y_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try standared tree with no limits \n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.61      0.64       450\n",
      "         1.0       0.59      0.73      0.65       630\n",
      "         2.0       0.57      0.47      0.51       150\n",
      "         3.0       0.81      0.82      0.82       420\n",
      "         4.0       0.79      0.75      0.77       690\n",
      "         5.0       0.89      0.85      0.87       720\n",
      "         6.0       0.90      0.71      0.80       270\n",
      "         7.0       0.06      0.08      0.07        60\n",
      "         8.0       0.83      0.88      0.85       690\n",
      "         9.0       0.56      0.43      0.49        90\n",
      "\n",
      "    accuracy                           0.75      4170\n",
      "   macro avg       0.67      0.63      0.65      4170\n",
      "weighted avg       0.76      0.75      0.75      4170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predict on test set\n",
    "y_pred_test_data = clf.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa: 0.7085977195439088\n",
      "MAE: 0.779136690647482\n"
     ]
    }
   ],
   "source": [
    "print(\"kappa:\",cohen_kappa_score(y_test, y_pred_test_data))\n",
    "print(\"MAE:\",mean_absolute_error(y_test, y_pred_test_data))# kappa greater then good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The same procedure for 2160 images of each class (the whole dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 12660\n"
     ]
    }
   ],
   "source": [
    "#equalize the data so all classes have the same amount of instances - smaller classes take their max\n",
    "\n",
    "def equilize(data):\n",
    "    train_combined_equal = []\n",
    "    for x in range(10):\n",
    "        count = 0\n",
    "        #while count < 2160:\n",
    "        for i in data :\n",
    "            if i[-1] == x and count < 2160:\n",
    "                train_combined_equal.append(i)\n",
    "                count += 1\n",
    "        \n",
    "    train_combined_equal = np.asarray(train_combined_equal)\n",
    "    np.random.shuffle(train_combined_equal)      \n",
    "    \n",
    "    return train_combined_equal\n",
    "\n",
    "train_combined_equal = equilize(train_data_combined)\n",
    "print(\"length:\",len(train_combined_equal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean: 80.957739030685\n",
      "test mean: 85.48841426858513\n"
     ]
    }
   ],
   "source": [
    "# Split data and lables that have undergone the same randomization process \n",
    "x_train = train_combined_equal[:,:-1]\n",
    "y_train = train_combined_equal[:, [-1]].reshape(len(train_combined_equal),)   \n",
    "\n",
    "\n",
    "x_train_all = train_data_combined[:,:-1]\n",
    "y_train_all = train_data_combined[:, [-1]].reshape(12660,)\n",
    "\n",
    "x_test = test_data_combined[:,:-1]\n",
    "y_test = test_data_combined[:, [-1]].reshape(4170,)\n",
    "\n",
    "#what is the mean of the data\n",
    "print(\"train mean:\",np.mean(x_train))\n",
    "print(\"test mean:\",np.mean(x_test))\n",
    "#shows that test set has been offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Reducing the number of attributes using opencv's reduce functionality as shown in the second python Lecture\n",
    "#  As seen in python lectures: https://vision.hw.ac.uk/webapps/blackboard/content/listContent.jsp?course_id=_94419_1&content_id=_3391865_1\n",
    "x_train_all = np.apply_along_axis(\n",
    "        func1d=lambda img: cv2.resize(img.reshape((48,48)), (num_pixels,num_pixels)),\n",
    "        axis =1, arr = x_train_all).reshape((-1,num_pixels*num_pixels))\n",
    "\n",
    "x_train = np.apply_along_axis(\n",
    "        func1d=lambda img: cv2.resize(img.reshape((48,48)), (num_pixels,num_pixels)),\n",
    "        axis =1, arr = x_train).reshape((-1,num_pixels*num_pixels))\n",
    "\n",
    "x_test  = np.apply_along_axis(\n",
    "        func1d=lambda img: cv2.resize(img.reshape((48,48)), (num_pixels,num_pixels)),\n",
    "        axis =1, arr = x_test).reshape((-1,num_pixels*num_pixels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_test = np.append(x_train,x_test, axis=0)\n",
    "y_train_test = np.append(y_train,y_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try standared tree with no limits \n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.68      0.66       450\n",
      "         1.0       0.70      0.78      0.73       630\n",
      "         2.0       0.83      0.47      0.60       150\n",
      "         3.0       0.87      0.85      0.86       420\n",
      "         4.0       0.78      0.78      0.78       690\n",
      "         5.0       0.88      0.95      0.91       720\n",
      "         6.0       0.81      0.83      0.82       270\n",
      "         7.0       0.26      0.23      0.25        60\n",
      "         8.0       0.90      0.85      0.88       690\n",
      "         9.0       0.65      0.33      0.44        90\n",
      "\n",
      "    accuracy                           0.79      4170\n",
      "   macro avg       0.73      0.68      0.69      4170\n",
      "weighted avg       0.79      0.79      0.79      4170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predict on test set\n",
    "y_pred_test_data = clf.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa: 0.7586583250892167\n",
      "MAE: 0.6345323741007194\n"
     ]
    }
   ],
   "source": [
    "print(\"kappa:\",cohen_kappa_score(y_test, y_pred_test_data))\n",
    "print(\"MAE:\",mean_absolute_error(y_test, y_pred_test_data))# kappa greater then good"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
